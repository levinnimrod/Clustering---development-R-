results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['best.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['best.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- file.choose() %>% read.csv
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
url <- file.choose(); source(url)
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(url, exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['best.classification']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
####################      EVALUATE THE MEAN DIFFERENCES                ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 4
results = cbind(
# Extract the mean values of the variables for the clustering groups from sample 1
aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i-1]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t,
# Extract the mean values of the variables for the clustering groups from sample 2
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i - 1 + 9]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t)   %>% as.data.frame()
results[1, ] <- c(rep(1, i), rep(2, i));
results <- t(results) %>% as.data.frame;
arrange(results, desc(total)) %>% t
####################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
# results = rep(NA, 12) %>% as.data.frame()
#
# for (i in seq(9)) {
#
# results[, i] =
# # Exctract the mean values of the variables for the clustering groups from sample 1
# (aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
#         arrange(desc(total)) -
# # then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
# aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
#   arrange(desc(total))) %>% abs %>%
#
#   apply(2, max) %>% round(2)
#
# }
# results <- results[-1, ] %>% as.data.frame()
# rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
# results
# results[1:10,] %>% colMeans() %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- file.choose() %>% read.csv
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
url <- file.choose(); source(url)
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(url, exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['best.classification']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
####################      EVALUATE THE MEAN DIFFERENCES                ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 4
results = cbind(
# Extract the mean values of the variables for the clustering groups from sample 1
aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i-1]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t,
# Extract the mean values of the variables for the clustering groups from sample 2
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i - 1 + 9]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t)   %>% as.data.frame()
results[1, ] <- c(rep(1, i), rep(2, i));
results <- t(results) %>% as.data.frame;
arrange(results, desc(total)) %>% t
####################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
# results = rep(NA, 12) %>% as.data.frame()
#
# for (i in seq(9)) {
#
# results[, i] =
# # Exctract the mean values of the variables for the clustering groups from sample 1
# (aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
#         arrange(desc(total)) -
# # then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
# aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
#   arrange(desc(total))) %>% abs %>%
#
#   apply(2, max) %>% round(2)
#
# }
# results <- results[-1, ] %>% as.data.frame()
# rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
# results
# results[1:10,] %>% colMeans() %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('..\\optimal loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df[1:9] = read.csv('..\\optimal loglikelihood')[-1, 12]
results$df[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 13]
# Set sample size
n = nrow(ldf[[1]]['best.classification'])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['best.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['best.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('..\\optimal loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df[1:9] = read.csv('..\\optimal loglikelihood')[-1, 12]
results$df[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 13]
# Set sample size
n = nrow(ldf[[1]]['best.classification'])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['best.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['best.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- file.choose() %>% read.csv
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
url <- file.choose(); source(url)
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(url, exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['best.classification']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
####################      EVALUATE THE MEAN DIFFERENCES                ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 4
results = cbind(
# Extract the mean values of the variables for the clustering groups from sample 1
aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i-1]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t,
# Extract the mean values of the variables for the clustering groups from sample 2
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i - 1 + 9]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t)   %>% as.data.frame()
results[1, ] <- c(rep(1, i), rep(2, i));
results <- t(results) %>% as.data.frame;
arrange(results, desc(total)) %>% t
####################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
# results = rep(NA, 12) %>% as.data.frame()
#
# for (i in seq(9)) {
#
# results[, i] =
# # Exctract the mean values of the variables for the clustering groups from sample 1
# (aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
#         arrange(desc(total)) -
# # then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
# aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
#   arrange(desc(total))) %>% abs %>%
#
#   apply(2, max) %>% round(2)
#
# }
# results <- results[-1, ] %>% as.data.frame()
# rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
# results
# results[1:10,] %>% colMeans() %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('..\\optimal loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df[1:9] = read.csv('..\\optimal loglikelihood')[-1, 12]
results$df[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 13]
# Set sample size
n = nrow(ldf[[1]]['best.classification'])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['best.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['best.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- file.choose() %>% read.csv
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
url <- file.choose(); source(url)
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(url, exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['best.classification']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
####################      EVALUATE THE MEAN DIFFERENCES                ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 4
results = cbind(
# Extract the mean values of the variables for the clustering groups from sample 1
aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i-1]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t,
# Extract the mean values of the variables for the clustering groups from sample 2
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i - 1 + 9]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) %>% t)   %>% as.data.frame()
results[1, ] <- c(rep(1, i), rep(2, i));
results <- t(results) %>% as.data.frame;
arrange(results, desc(total)) %>% t
####################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
# results = rep(NA, 12) %>% as.data.frame()
#
# for (i in seq(9)) {
#
# results[, i] =
# # Exctract the mean values of the variables for the clustering groups from sample 1
# (aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
#         arrange(desc(total)) -
# # then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
# aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
#   arrange(desc(total))) %>% abs %>%
#
#   apply(2, max) %>% round(2)
#
# }
# results <- results[-1, ] %>% as.data.frame()
# rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
# results
# results[1:10,] %>% colMeans() %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('..\\optimal loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df[1:9] = read.csv('..\\optimal loglikelihood')[-1, 12]
results$df[10:18] <- read.csv('..\\optimal loglikelihood')[-1, 13]
# Set sample size
n = nrow(ldf[[1]]['best.classification'])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['best.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['best.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
