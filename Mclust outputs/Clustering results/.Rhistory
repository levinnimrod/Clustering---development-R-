x <- scale(file)
partial <- Mclust(x, G = 4 )
partial <- Mclust(file[1:5], G = 4 )
partial <- Mclust(file[2], G = 4 )
partial <- Mclust(file[2, ], G = 4 )
partial <- Mclust(file[1:2, ], G = 4 )
partial <- Mclust(file[2:3, ], G = 4 )
partial <- Mclust(file[3:4, ], G = 4 )
file <- cddq[, 50:59]
partial <- Mclust(file[3:4, ], G = 4 )
library(tidyLPA)
estimate_profiles(x)
estimate_profiles(x, n_profiles = 4)
View(x)
file <- cddq[, 50:59]
file[complete.cases(file)]
file[complete.cases(file), ]
file[!complete.cases(file), ]
file <- cddq[, 50:59]
file <- file[complete.cases(file), ]
x <- t(scale(t(file))) %>% as.data.frame
partial <- Mclust(file[3:4, ], G = 4 )
partial <- Mclust(file, G = 4 )
partial$parameters$mean %>% round(2)
file <- cddq[, 50:59]
file <- file[complete.cases(file), ]
partial$parameters$mean %>% round(2)
partial <- Mclust(file, G = 4 )
partial$parameters$mean %>% round(2)
install.packages("Rserve")
install.packages("shiny")
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(shiny)
install.packages('shiny')
library(shiny)
install.packages('shiny')
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2); library(lsr)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- read.csv('../../../df.csv')
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
source('../../R Scripts/zero-variance validity check (function).R')
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      CALCULATE RI SCORE                ####################
sample1$LI <- (sample1$Lp + sample1$Lo + sample1$Lp + sample1$Ls) / 4 %>% round(2)
sample2$LI <- (sample2$Lp + sample2$Lo + sample2$Lp + sample2$Ls) / 4 %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
uncertainty = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['result.classification']
#  uncertainty[i] = ldf[[i]]['result.uncertainty']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
# ####################      EVALUATE THE MEAN DIFFERENCES - Ri, Rd, LI, Ie                ####################
# names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
#
# # define which two solutions you want to compare (i = ?)
# i = 4
#
# aggregate(sample1[c('Ri', 'Rd', 'LI', 'Ie')], by = as.data.frame(classifications[names[i-1]]), FUN = mean)
#
#
# # Extract the mean values of the variables for the clustering groups from sample 1
# results = cbind(aggregate(sample1[c('Ri', 'Rd', 'LI', 'Ie', 'total')], by = as.data.frame(classifications[names[i-1]]),
#                   FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
#
# # Extract the mean values of the variables for the clustering groups from sample 2
# results = results %>% cbind(cbind(aggregate(sample2[c('Ri', 'Rd', 'LI', 'Ie', 'total')], by = as.data.frame(classifications[names[i-1+9]]),
#                    FUN = mean) %>% round(2), table(classifications[names[i-1+9]])) %>% arrange(desc(total)) %>% t)
#
#
# results[1, ] <- c(rep(1, i), rep(2, i)); results <- t(results) %>% as.data.frame;
# results <- arrange(results, desc(total)) %>% t %>% as.data.frame();
# results
####################      EVALUATE THE MEAN DIFFERENCES - ALL 10 DIMENSIONS               ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 6
# Extract the mean values of the variables for the clustering groups from sample 1
results = cbind(aggregate(sample1[(ldf[[i]]['result.uncertainty'] <= .20), 7:17], by = as.data.frame(classifications[names[i-1]][(ldf[[i]]['result.uncertainty'] <= .20)]),
FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
# Extract the mean values of the variables for the clustering groups from sample 2
results = results %>% cbind(cbind(aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i-1+9]]),
FUN = mean) %>% round(2), table(classifications[names[i-1+9]]))  %>% arrange(desc(total)) %>% t)
results[1, ] <- c(rep(1, i), rep(2, i)); results <- t(results) %>% as.data.frame;
results <- arrange(results, desc(total)) %>% t %>% as.data.frame();
results
###################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
results = rep(NA, 12) %>% as.data.frame()
for (i in seq(9)) {
results[, i] =
# Exctract the mean values of the variables for the clustering groups from sample 1
(aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) -
# then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
arrange(desc(total))) %>% abs %>%
apply(2, max) %>% round(2)
}
results <- results[-1, ] %>% as.data.frame()
rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
results
results[1:10,] %>% colMeans() %>% round(2)
# define which two solutions you want to compare (i = ?)
i = 13
# Extract the mean values of the variables for the clustering groups from sample 1
results = cbind(aggregate(sample1[(ldf[[i]]['result.uncertainty'] <= .20), 7:17], by = as.data.frame(classifications[names[i-1]][(ldf[[i]]['result.uncertainty'] <= .20)]),
FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
# Extract the mean values of the variables for the clustering groups from sample 2
results = results %>% cbind(cbind(aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i-1+9]]),
FUN = mean) %>% round(2), table(classifications[names[i-1+9]]))  %>% arrange(desc(total)) %>% t)
# define which two solutions you want to compare (i = ?)
i = 4
# Extract the mean values of the variables for the clustering groups from sample 1
results = cbind(aggregate(sample1[(ldf[[i]]['result.uncertainty'] <= .20), 7:17], by = as.data.frame(classifications[names[i-1]][(ldf[[i]]['result.uncertainty'] <= .20)]),
FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
# Extract the mean values of the variables for the clustering groups from sample 2
results = results %>% cbind(cbind(aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i-1+9]]),
FUN = mean) %>% round(2), table(classifications[names[i-1+9]]))  %>% arrange(desc(total)) %>% t)
results[1, ] <- c(rep(1, i), rep(2, i)); results <- t(results) %>% as.data.frame;
results <- arrange(results, desc(total)) %>% t %>% as.data.frame();
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(ggplot2); library(lsr)
####################      LOAD THE CLUSTERING SOLUTIONS                ####################
setwd(choose.dir())
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      LOAD TIDY FILES AND SUBSET FOR THE RELEVANT SAMPLE                ####################
cddq <- read.csv('../../../df.csv')
# get only participants with RCA based in the USA
cddq <- cddq[!is.na(cddq$RCA) & cddq$Country == "USA", ]
# remove participants with no difference in responses
source('../../R Scripts/zero-variance validity check (function).R')
cddq <- cddq[!exclude(cddq[, c(49:51, 53:56, 58:60)]) == 0, ]; remove(exclude)
####################      CREATE TWO RANDOM SAMPLES                ####################
sample1 <- cddq[seq(1, nrow(cddq), by = 2), ]; sample1 <- sample1[, -1];
sample2 <- cddq[seq(2, nrow(cddq), by = 2), ]; sample2 <- sample2[, -1];
remove(cddq)
# get only the variables you need
sample1 <- (sample1[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
sample2 <- (sample2[, c(4:5, 8:11, 48:50, 52:55, 57:59, 61)]) %>% round(2)
####################      CALCULATE RI SCORE                ####################
sample1$LI <- (sample1$Lp + sample1$Lo + sample1$Lp + sample1$Ls) / 4 %>% round(2)
sample2$LI <- (sample2$Lp + sample2$Lo + sample2$Lp + sample2$Ls) / 4 %>% round(2)
####################      EXCTRACT CLASSIFICATIONS FROM THE SOLUTIONS                ####################
classifications = data.frame(rep(NA, nrow(ldf[[1]])))
uncertainty = data.frame(rep(NA, nrow(ldf[[1]])))
for (i in seq(18)){
classifications[i] = ldf[[i]]['result.classification']
#  uncertainty[i] = ldf[[i]]['result.uncertainty']
}
classifications <- cbind(classifications[,2:9], classifications[,1], classifications[,11:18], classifications[,10])
colnames(classifications) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", seq(2,10))
# ####################      EVALUATE THE MEAN DIFFERENCES - Ri, Rd, LI, Ie                ####################
# names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
#
# # define which two solutions you want to compare (i = ?)
# i = 4
#
# aggregate(sample1[c('Ri', 'Rd', 'LI', 'Ie')], by = as.data.frame(classifications[names[i-1]]), FUN = mean)
#
#
# # Extract the mean values of the variables for the clustering groups from sample 1
# results = cbind(aggregate(sample1[c('Ri', 'Rd', 'LI', 'Ie', 'total')], by = as.data.frame(classifications[names[i-1]]),
#                   FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
#
# # Extract the mean values of the variables for the clustering groups from sample 2
# results = results %>% cbind(cbind(aggregate(sample2[c('Ri', 'Rd', 'LI', 'Ie', 'total')], by = as.data.frame(classifications[names[i-1+9]]),
#                    FUN = mean) %>% round(2), table(classifications[names[i-1+9]])) %>% arrange(desc(total)) %>% t)
#
#
# results[1, ] <- c(rep(1, i), rep(2, i)); results <- t(results) %>% as.data.frame;
# results <- arrange(results, desc(total)) %>% t %>% as.data.frame();
# results
####################      EVALUATE THE MEAN DIFFERENCES - ALL 10 DIMENSIONS               ####################
names <- c(paste0('S1_G', 2:10), paste0('S2_G', 2:10))
# define which two solutions you want to compare (i = ?)
i = 4
# Extract the mean values of the variables for the clustering groups from sample 1
results = cbind(aggregate(sample1[(ldf[[i]]['result.uncertainty'] <= .20), 7:17], by = as.data.frame(classifications[names[i-1]][(ldf[[i]]['result.uncertainty'] <= .20)]),
FUN = mean) %>% round(2), table(classifications[names[i-1]])) %>% arrange(desc(total)) %>% t
# Extract the mean values of the variables for the clustering groups from sample 2
results = results %>% cbind(cbind(aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i-1+9]]),
FUN = mean) %>% round(2), table(classifications[names[i-1+9]]))  %>% arrange(desc(total)) %>% t)
results[1, ] <- c(rep(1, i), rep(2, i)); results <- t(results) %>% as.data.frame;
results <- arrange(results, desc(total)) %>% t %>% as.data.frame();
results
###################      COMPUTE THE MEAN OF THE MAXIMUM DIFFERENCE BETWEEN SAMPLES ACROSS THE 10 SCORES                ####################
results = rep(NA, 12) %>% as.data.frame()
for (i in seq(9)) {
results[, i] =
# Exctract the mean values of the variables for the clustering groups from sample 1
(aggregate(sample1[, 7:17], by = as.data.frame(classifications[names[i]]), FUN = mean) %>% round(2) %>%
arrange(desc(total)) -
# then substract the mean values of the variables for the clustering groups from sample 2 (get the absolute values)
aggregate(sample2[, 7:17], by = as.data.frame(classifications[names[i + 9]]), FUN = mean) %>%
arrange(desc(total))) %>% abs %>%
apply(2, max) %>% round(2)
}
results <- results[-1, ] %>% as.data.frame()
rownames(results) <- colnames(sample1[, 7:17]); colnames(results) <- c(seq(2, 10))
results
results[1:10,] %>% colMeans() %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyr); library(ggplot2); library(gridExtra)
graphics.off()
####################      DERIVE THE MAXIMUM LL FROM EACH RANDOM START                ####################
setwd(choose.dir()) # choose the directory "Optimal Likelihood" (pc)
setwd('/Users/nimrodlevin/Desktop/Study 4/Mclust outputs/Optimal Likelihood/') # mac
files <- list.files()
ldf = rep(NA,2) %>% as.data.frame()
for (i in seq(length(files)-2)) {
ldf[1:9, i] <- read.table(as.character(i), sep = ',', header = TRUE)[-1, 2] %>% round(2)
ldf[10:18, i] <- read.table(as.character(i), sep = ',', header = TRUE)[-1, 3] %>% round(2)
}
colnames(ldf) <- paste0("Seed_", seq(length(files)-1))
# And transpose the data set
ldf <- ldf %>% t %>% as.data.frame()
colnames(ldf) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", rep(2:10))
####################      PLOT THE SOLUTIONS WITH ALL DATA POINTS                ####################
plot1_2 <- ggplot(ldf, aes(x=S1_G2, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_3 <- ggplot(ldf, aes(x=S1_G3, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_4 <- ggplot(ldf, aes(x=S1_G4, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_5 <- ggplot(ldf, aes(x=S1_G5, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_6 <- ggplot(ldf, aes(x=S1_G6, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_7 <- ggplot(ldf, aes(x=S1_G7, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_8 <- ggplot(ldf, aes(x=S1_G8, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_9 <- ggplot(ldf, aes(x=S1_G9, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_10 <- ggplot(ldf, aes(x=S1_G10, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_2 <- ggplot(ldf, aes(x=S2_G2, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_3 <- ggplot(ldf, aes(x=S2_G3, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_4 <- ggplot(ldf, aes(x=S2_G4, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_5 <- ggplot(ldf, aes(x=S2_G5, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_6 <- ggplot(ldf, aes(x=S2_G6, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_7 <- ggplot(ldf, aes(x=S2_G7, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_8 <- ggplot(ldf, aes(x=S2_G8, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_9 <- ggplot(ldf, aes(x=S2_G9, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_10 <- ggplot(ldf, aes(x=S2_G10, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
grid.arrange(plot1_2, plot2_2, plot1_3, plot2_3, plot1_4, plot2_4, plot1_5, plot2_5,
plot1_6, plot2_6, plot1_7, plot2_7, plot1_8, plot2_8, plot1_9, plot2_9, plot1_10, plot2_10,
nrow = 9, ncol = 2)
####################      CALCULATE PERCENTAGE OF PARTICIPANTS WITH CR < 2 FOR CLUSTER ASSIGNMENT                ####################
# get the relevant files with the probabilities for cluster assignment
#files <- paste0('..\\Clustering results\\', list.files('..\\Clustering results')) # pc
files <- paste0('../Clustering results/', list.files('../Clustering results')) # mac
ldf <- lapply(files, read.csv); remove(files)
# extract the maximum p and the second maximum p and calculate its ratio
i = 14; limit <- ldf[[i]] %>% ncol - 2
result <- ldf[[i]][2:limit] %>% apply(MARGIN = 1, sort) ; result <- result %>% t
result <- result[, limit-1] / result[, limit-2]; result <- result < 2
# summarize results by groups (count of ratios smaller than 2)
aggregate(result, by = as.data.frame(ldf[[i]]['result.classification']), FUN = sum)
table(ldf[[i]]['result.classification'])
####################      CALCULATE PERCENTAGE OF PARTICIPANTS WITH P < .80 FOR CLUSTER ASSIGNMENT                ####################
# extract the maximum p and the second maximum p and calculate its ratio
i = 14
result <- ldf[[i]][c('result.uncertainty', 'result.classification')]
aggregate(result$result.uncertainty > .2, by = as.data.frame(result$result.classification), FUN = mean)
table(result$result.classification)
# Compute p < .80 at the Solution level (across profiles)
(ldf[[i]]['result.uncertainty'] > .20) %>% sum/44.59 %>% round(2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir()) # pc
#setwd('/Users/nimrodlevin/Desktop/Study 4/Mclust outputs/Clustering results/') # mac
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('../maximum loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('../maximum loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df<- rep(seq(2:10)*11,2)
# Set sample size
n = nrow(ldf[[1]])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['result.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['result.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyr); library(ggplot2); library(gridExtra)
graphics.off()
####################      DERIVE THE MAXIMUM LL FROM EACH RANDOM START                ####################
setwd(choose.dir()) # choose the directory "Optimal Likelihood" (pc)
setwd('/Users/nimrodlevin/Desktop/Study 4/Mclust outputs/Optimal Likelihood/') # mac
files <- list.files()
ldf = rep(NA,2) %>% as.data.frame()
for (i in seq(length(files)-2)) {
ldf[1:9, i] <- read.table(as.character(i), sep = ',', header = TRUE)[-1, 2] %>% round(2)
ldf[10:18, i] <- read.table(as.character(i), sep = ',', header = TRUE)[-1, 3] %>% round(2)
}
colnames(ldf) <- paste0("Seed_", seq(length(files)-1))
# And transpose the data set
ldf <- ldf %>% t %>% as.data.frame()
colnames(ldf) <- paste0("S", c(rep(1,9), rep(2, 9)), "_G", rep(2:10))
####################      PLOT THE SOLUTIONS WITH ALL DATA POINTS                ####################
plot1_2 <- ggplot(ldf, aes(x=S1_G2, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_3 <- ggplot(ldf, aes(x=S1_G3, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_4 <- ggplot(ldf, aes(x=S1_G4, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_5 <- ggplot(ldf, aes(x=S1_G5, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_6 <- ggplot(ldf, aes(x=S1_G6, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_7 <- ggplot(ldf, aes(x=S1_G7, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_8 <- ggplot(ldf, aes(x=S1_G8, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_9 <- ggplot(ldf, aes(x=S1_G9, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot1_10 <- ggplot(ldf, aes(x=S1_G10, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_2 <- ggplot(ldf, aes(x=S2_G2, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_3 <- ggplot(ldf, aes(x=S2_G3, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_4 <- ggplot(ldf, aes(x=S2_G4, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_5 <- ggplot(ldf, aes(x=S2_G5, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_6 <- ggplot(ldf, aes(x=S2_G6, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_7 <- ggplot(ldf, aes(x=S2_G7, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_8 <- ggplot(ldf, aes(x=S2_G8, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_9 <- ggplot(ldf, aes(x=S2_G9, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
plot2_10 <- ggplot(ldf, aes(x=S2_G10, y=c(0), alpha = 0.3 )) + geom_count() +
theme(axis.ticks = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(),
legend.position = 'none')
grid.arrange(plot1_2, plot2_2, plot1_3, plot2_3, plot1_4, plot2_4, plot1_5, plot2_5,
plot1_6, plot2_6, plot1_7, plot2_7, plot1_8, plot2_8, plot1_9, plot2_9, plot1_10, plot2_10,
nrow = 9, ncol = 2)
####################      RELEVANT LIBRARIES AND WORKING DIRECTORY                ####################
remove(list = ls())
library(dplyr); library(tidyLPA)
####################      LOAD ALL SOLUTIONS                ####################
setwd(choose.dir()) # pc
#setwd('/Users/nimrodlevin/Desktop/Study 4/Mclust outputs/Clustering results/') # mac
files <- list.files()
ldf <- lapply(files, read.csv); remove(files)
####################      SET THE RESULTS TABLE AND ADD THE LL VALUES                ####################
# set the results table
results = c(rep(1,9), rep(2, 9))
results <- as.data.frame(results);
results$profiles <- c(rep(2:10,2)); colnames(results) <- c('Sample', 'Profiles')
# extract the log-likelihood values
results$LL = NA
results$LL[1:9] <- read.csv('../maximum loglikelihood')[-1, 2]
results$LL[10:18] <- read.csv('../maximum loglikelihood')[-1, 3]
# set the relevant degrees of freedom
results$df<- rep(seq(2:10)*11,2)
# Set sample size
n = nrow(ldf[[1]])
####################     CALCULATE THE LRT p-values                ####################
results$LRTp = NA
for (i in c(seq(1,8), seq(10,17))) {
results$LRTp[i] = calc_lrt(n, results$LL[i], results$df[i], results$Profiles[i],
results$LL[i + 1], results$df[i + 1], results$Profiles[i + 1])[4] %>% round(2)
}
# reorder rows according to file order
results <- rbind(results[9, ], results[1:8,], results[18,], results[10:17,])
####################     CALCULATE THE AIC + BIC VALUEs                ####################
results$AIC = -2*results$LL+2*results$df
results$BIC = -2*results$LL + results$df*log(n)
results$SaBIC = -2*results$LL + results$df*log((n + 2) / 24)
####################     CALCULATE THE RELATIVE ENTROPY VALUE                ####################
results$entropy = NA
for (i in seq(2, 19)) {
results$entropy[i - 1] <- (-log(1/results$Profiles[i-1])*n +
sum(ldf[[i-1]][,2:results$Profiles[i-1]]*log(ldf[[i-1]][,2:results$Profiles[i-1]], 2), na.rm = TRUE)) /
(-log(1/results$Profiles[i-1])*n)
results$entropy <- round(results$entropy,2)
}
####################      GET MIN AND MAX NUMBER OF PARTICIPANTS IN A GROUP                ####################
# get minimum number of participants
results$min = NA
results$min_per = NA
results$max = NA
results$max_per = NA
for (i in seq(1, 18)) {
results$min[i] = ldf[[i]]['result.classification'] %>% table %>% min
results$min_per[i] = 100*results$min[i]/n ; results$min_per <- results$min_per %>% round(2)
results$max[i] = ldf[[i]]['result.classification'] %>% table %>% max
results$max_per[i] = 100*results$max[i]/n ; results$max_per <- results$max_per %>% round(2)
}
# reorder rows according to profiles
results <- rbind(results[2:9, ], results[1,], results[11:18,], results[10,])
results <- cbind(results[, 1:4], results[, 6:8], results[, 5], results[, 9:13]);
colnames(results) <- c("Sample", "Profiles", "LL", "df", "AIC", "BIC", "SaBIC",
"LRTp", "Entropy", "min", "min_per", "max", "max_per")
results
results; x <- results
View(x)
